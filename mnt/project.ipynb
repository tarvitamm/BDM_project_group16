{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nupyter Jotebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion and Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"input/sample_nyc_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"NYC Taxi Analysis\").getOrCreate()\n",
    "\n",
    "df_spark = spark.read.csv(\"input/sample_nyc_data.csv\", header=True, inferSchema=True).cache()\n",
    "\n",
    "df_selected = df_spark.select(\"medallion\", \n",
    "                        \"pickup_datetime\", \"pickup_longitude\", \"pickup_latitude\", \n",
    "                        \"dropoff_datetime\", \"dropoff_longitude\", \"dropoff_latitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopandas\n",
      "  Using cached geopandas-1.0.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: numpy>=1.22 in /opt/conda/lib/python3.11/site-packages (from geopandas) (1.26.4)\n",
      "Collecting pyogrio>=0.7.2 (from geopandas)\n",
      "  Downloading pyogrio-0.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from geopandas) (24.1)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from geopandas) (2.0.3)\n",
      "Collecting pyproj>=3.3.0 (from geopandas)\n",
      "  Downloading pyproj-3.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting shapely>=2.0.0 (from geopandas)\n",
      "  Downloading shapely-2.0.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.4.0->geopandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.4.0->geopandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.4.0->geopandas) (2024.2)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from pyogrio>=0.7.2->geopandas) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.16.0)\n",
      "Using cached geopandas-1.0.1-py3-none-any.whl (323 kB)\n",
      "Downloading pyogrio-0.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (24.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyproj-3.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading shapely-2.0.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: shapely, pyproj, pyogrio, geopandas\n",
      "Successfully installed geopandas-1.0.1 pyogrio-0.10.0 pyproj-3.7.1 shapely-2.0.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>borough</th>\n",
       "      <th>boroughCode</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((-74.01675 40.69334, -74.0154 40.6930...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((-73.92641 40.87762, -73.9263 40.8774...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((-73.92134 40.80085, -73.92031 40.799...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((-73.93805 40.78083, -73.93779 40.780...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((-73.9418 40.76905, -73.94286 40.7683...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      borough  boroughCode                                           geometry\n",
       "51  Manhattan            1  POLYGON ((-74.01675 40.69334, -74.0154 40.6930...\n",
       "72  Manhattan            1  POLYGON ((-73.92641 40.87762, -73.9263 40.8774...\n",
       "71  Manhattan            1  POLYGON ((-73.92134 40.80085, -73.92031 40.799...\n",
       "70  Manhattan            1  POLYGON ((-73.93805 40.78083, -73.93779 40.780...\n",
       "69  Manhattan            1  POLYGON ((-73.9418 40.76905, -73.94286 40.7683..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install geopandas\n",
    "import geopandas as gpd\n",
    "\n",
    "boroughs = gpd.read_file(\"input/nyc-boroughs.geojson\")\n",
    "boroughs = boroughs.sort_values(by=\"boroughCode\", ascending=True)\n",
    "\n",
    "boroughs_list = [(row[\"borough\"], row[\"geometry\"]) for _, row in boroughs.iterrows()]\n",
    "\n",
    "sc = SparkSession.builder.getOrCreate().sparkContext\n",
    "boroughs_bc = sc.broadcast(boroughs_list)\n",
    "\n",
    "boroughs[[\"borough\", \"boroughCode\", \"geometry\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "\n",
    "def get_borough(lat, lon):\n",
    "    \"\"\"Returns the borough name for given latitude and longitude.\"\"\"\n",
    "    if lat is None or lon is None:  \n",
    "        return \"Unknown\"\n",
    "    \n",
    "    point = Point(lon, lat)\n",
    "    \n",
    "    for borough_name, polygon in boroughs_bc.value:\n",
    "        if polygon.contains(point):\n",
    "            return borough_name\n",
    "    return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "get_borough_udf = udf(get_borough, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|dropoff_borough|\n",
      "+---------------+\n",
      "|Queens         |\n",
      "|Unknown        |\n",
      "|Brooklyn       |\n",
      "|Staten Island  |\n",
      "|Manhattan      |\n",
      "|Bronx          |\n",
      "+---------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6444"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selected = df_selected.withColumn(\"pickup_borough\", get_borough_udf(df_selected[\"pickup_latitude\"], df_selected[\"pickup_longitude\"]))\n",
    "df_selected = df_selected.withColumn(\"dropoff_borough\", get_borough_udf(df_selected[\"dropoff_latitude\"], df_selected[\"dropoff_longitude\"]))\n",
    "df_selected.select(\"dropoff_borough\").distinct().show(truncate=False)\n",
    "\n",
    "df_selected.select(\"medallion\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUERY 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|pickup_datetime|\n",
      "+---------------+\n",
      "|01-01-13 15:11 |\n",
      "|06-01-13 00:18 |\n",
      "|05-01-13 18:49 |\n",
      "|07-01-13 23:54 |\n",
      "|07-01-13 23:25 |\n",
      "|07-01-13 15:27 |\n",
      "|08-01-13 11:01 |\n",
      "|07-01-13 12:39 |\n",
      "|07-01-13 18:15 |\n",
      "|07-01-13 15:33 |\n",
      "+---------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- medallion: string (nullable = true)\n",
      " |-- pickup_datetime: string (nullable = true)\n",
      " |-- pickup_longitude: double (nullable = true)\n",
      " |-- pickup_latitude: double (nullable = true)\n",
      " |-- dropoff_datetime: string (nullable = true)\n",
      " |-- dropoff_longitude: double (nullable = true)\n",
      " |-- dropoff_latitude: double (nullable = true)\n",
      " |-- pickup_borough: string (nullable = true)\n",
      " |-- dropoff_borough: string (nullable = true)\n",
      "\n",
      "+---------------+\n",
      "|pickup_datetime|\n",
      "+---------------+\n",
      "|13-01-13 04:09 |\n",
      "|13-01-13 11:30 |\n",
      "|13-01-13 10:44 |\n",
      "|13-01-13 10:42 |\n",
      "|13-01-13 09:35 |\n",
      "|13-01-13 08:21 |\n",
      "|13-01-13 04:55 |\n",
      "|13-01-13 03:37 |\n",
      "|13-01-13 00:49 |\n",
      "|13-01-13 03:16 |\n",
      "|13-01-13 12:47 |\n",
      "|10-01-13 15:34 |\n",
      "|13-01-13 05:24 |\n",
      "|13-01-13 08:17 |\n",
      "|13-01-13 12:14 |\n",
      "|13-01-13 10:41 |\n",
      "|13-01-13 13:34 |\n",
      "|13-01-13 04:11 |\n",
      "|13-01-13 03:26 |\n",
      "|13-01-13 08:20 |\n",
      "+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_selected.select(\"pickup_datetime\").show(10, truncate=False)\n",
    "df_selected.printSchema()\n",
    "\n",
    "df_selected.select(\"pickup_datetime\").distinct().show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+-------------------+----------+\n",
      "|pickup_datetime    |pickup_ts |dropoff_datetime   |dropoff_ts|\n",
      "+-------------------+----------+-------------------+----------+\n",
      "|2013-01-01 15:11:00|1357053060|2013-01-01 15:18:00|1357053480|\n",
      "|2013-01-06 00:18:00|1357431480|2013-01-06 00:22:00|1357431720|\n",
      "|2013-01-05 18:49:00|1357411740|2013-01-05 18:54:00|1357412040|\n",
      "|2013-01-07 23:54:00|1357602840|2013-01-07 23:58:00|1357603080|\n",
      "|2013-01-07 23:25:00|1357601100|2013-01-07 23:34:00|1357601640|\n",
      "|2013-01-07 15:27:00|1357572420|2013-01-07 15:38:00|1357573080|\n",
      "|2013-01-08 11:01:00|1357642860|2013-01-08 11:08:00|1357643280|\n",
      "|2013-01-07 12:39:00|1357562340|2013-01-07 13:10:00|1357564200|\n",
      "|2013-01-07 18:15:00|1357582500|2013-01-07 18:20:00|1357582800|\n",
      "|2013-01-07 15:33:00|1357572780|2013-01-07 15:49:00|1357573740|\n",
      "+-------------------+----------+-------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import unix_timestamp, to_timestamp, col\n",
    "\n",
    "df_selected = df_selected.withColumn(\"pickup_datetime\", to_timestamp(col(\"pickup_datetime\"), \"dd-MM-yy HH:mm\"))\n",
    "df_selected = df_selected.withColumn(\"dropoff_datetime\", to_timestamp(col(\"dropoff_datetime\"), \"dd-MM-yy HH:mm\"))\n",
    "\n",
    "df_selected = df_selected.withColumn(\"pickup_ts\", unix_timestamp(col(\"pickup_datetime\")))\n",
    "df_selected = df_selected.withColumn(\"dropoff_ts\", unix_timestamp(col(\"dropoff_datetime\")))\n",
    "\n",
    "df_selected.select(\"pickup_datetime\", \"pickup_ts\", \"dropoff_datetime\", \"dropoff_ts\").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6444"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lag, sum as spark_sum, when\n",
    "\n",
    "df_selected = df_selected.withColumn(\"duration\", col(\"dropoff_ts\") - col(\"pickup_ts\"))\n",
    "df_selected = df_selected.select(\"medallion\", \"pickup_borough\", \"dropoff_borough\", \"pickup_ts\", \"dropoff_ts\", \"duration\")\n",
    "\n",
    "df_selected.select(\"medallion\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6444"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, lag, sum as spark_sum\n",
    "\n",
    "window_spec = Window.partitionBy(\"medallion\").orderBy(\"pickup_ts\")\n",
    "\n",
    "df_utilization = df_selected.withColumn(\"prev_dropoff\", lag(\"dropoff_ts\").over(window_spec))\n",
    "df_utilization = df_utilization.withColumn(\"idle_time\", when(col(\"prev_dropoff\").isNotNull(), col(\"pickup_ts\") - col(\"prev_dropoff\")).otherwise(None))\n",
    "\n",
    "idle_time = df_utilization.groupBy(\"medallion\").agg(spark_sum(\"idle_time\").alias(\"total_idle_time\"))\n",
    "\n",
    "df_selected.select(\"medallion\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|           medallion|total_occupied_time|\n",
      "+--------------------+-------------------+\n",
      "|0F621E366CFE63044...|              19020|\n",
      "|223670562219093D6...|               6120|\n",
      "|496036713FC662D71...|               3660|\n",
      "|4F4CA97166A04A455...|               9360|\n",
      "|5803D6EAD49AEAA82...|               1620|\n",
      "|59DF6039EC312EE6D...|              15900|\n",
      "|5CCB4924B158F945B...|              18780|\n",
      "|618BB39CEEAE5E9A6...|              12000|\n",
      "|6AFD7E44A278CFD00...|               3960|\n",
      "|72EAFBA3FB9F0507C...|              11580|\n",
      "+--------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6444"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import sum as spark_sum, col\n",
    "\n",
    "window_spec = Window.partitionBy(\"medallion\")\n",
    "\n",
    "occupied_time = df_selected.groupBy(\"medallion\").agg(spark_sum(\"duration\").alias(\"total_occupied_time\"))\n",
    "idle_time = df_utilization.groupBy(\"medallion\").agg(spark_sum(\"idle_time\").alias(\"total_idle_time\"))\n",
    "\n",
    "df_final_utilization = occupied_time.join(idle_time, on=\"medallion\", how=\"inner\")\n",
    "\n",
    "df_final_utilization = df_final_utilization.cache()\n",
    "\n",
    "df_final_utilization.select(\"medallion\", \"total_occupied_time\").distinct().show(10)\n",
    "df_final_utilization.select(\"medallion\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+---------------+----------+----------+--------+------------+---------+\n",
      "|           medallion|pickup_borough|dropoff_borough| pickup_ts|dropoff_ts|duration|prev_dropoff|idle_time|\n",
      "+--------------------+--------------+---------------+----------+----------+--------+------------+---------+\n",
      "|002E3B405B6ABEA23...|     Manhattan|      Manhattan|1358047920|1358048340|     420|        NULL|     NULL|\n",
      "|002E3B405B6ABEA23...|     Manhattan|      Manhattan|1358049900|1358051700|    1800|  1358048340|     1560|\n",
      "|002E3B405B6ABEA23...|     Manhattan|      Manhattan|1358052180|1358052720|     540|  1358051700|      480|\n",
      "|002E3B405B6ABEA23...|        Queens|      Manhattan|1358079060|1358080920|    1860|  1358052720|    26340|\n",
      "|002E3B405B6ABEA23...|     Manhattan|      Manhattan|1358081940|1358082840|     900|  1358080920|     1020|\n",
      "|002E3B405B6ABEA23...|     Manhattan|      Manhattan|1358083320|1358084040|     720|  1358082840|      480|\n",
      "|002E3B405B6ABEA23...|     Manhattan|      Manhattan|1358084160|1358084520|     360|  1358084040|      120|\n",
      "|002E3B405B6ABEA23...|     Manhattan|      Manhattan|1358086620|1358087460|     840|  1358084520|     2100|\n",
      "|002E3B405B6ABEA23...|     Manhattan|      Manhattan|1358087520|1358088180|     660|  1358087460|       60|\n",
      "|002E3B405B6ABEA23...|     Manhattan|         Queens|1358092980|1358095080|    2100|  1358088180|     4800|\n",
      "+--------------------+--------------+---------------+----------+----------+--------+------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final_utilization = occupied_time.join(idle_time, on=\"medallion\", how=\"inner\")\n",
    "\n",
    "df_final_utilization = df_final_utilization.withColumn(\n",
    "    \"utilization\",\n",
    "    when(col(\"total_occupied_time\") + col(\"total_idle_time\") > 0,\n",
    "         col(\"total_occupied_time\") / (col(\"total_occupied_time\") + col(\"total_idle_time\"))\n",
    "    ).otherwise(0)\n",
    ")\n",
    "\n",
    "\n",
    "df_utilization.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+---------------+-----------+\n",
      "|           medallion|total_occupied_time|total_idle_time|utilization|\n",
      "+--------------------+-------------------+---------------+-----------+\n",
      "|0F621E366CFE63044...|              19020|          30600|       0.38|\n",
      "|223670562219093D6...|               6120|          14580|        0.3|\n",
      "|496036713FC662D71...|               3660|          57120|       0.06|\n",
      "|4F4CA97166A04A455...|               9360|          38820|       0.19|\n",
      "|5803D6EAD49AEAA82...|               1620|           NULL|        0.0|\n",
      "|59DF6039EC312EE6D...|              15900|          38880|       0.29|\n",
      "|5CCB4924B158F945B...|              18780|          23520|       0.44|\n",
      "|618BB39CEEAE5E9A6...|              12000|          34800|       0.26|\n",
      "|6AFD7E44A278CFD00...|               3960|           8640|       0.31|\n",
      "|72EAFBA3FB9F0507C...|              11580|          13800|       0.46|\n",
      "+--------------------+-------------------+---------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import round\n",
    "\n",
    "df_final_utilization = df_final_utilization.withColumn(\"utilization\", round(col(\"utilization\"), 2))\n",
    "\n",
    "df_final_utilization.select(\"medallion\", \"total_occupied_time\", \"total_idle_time\", \"utilization\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUERY 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+----------+--------------+---------+\n",
      "|           medallion|dropoff_borough|dropoff_ts|next_pickup_ts|wait_time|\n",
      "+--------------------+---------------+----------+--------------+---------+\n",
      "|000318C2E3E638158...|      Manhattan|1358052900|    1358070300|    17400|\n",
      "|000318C2E3E638158...|        Unknown|1358070420|    1358070960|      540|\n",
      "|000318C2E3E638158...|        Unknown|1358071440|    1358071500|       60|\n",
      "|000318C2E3E638158...|        Unknown|1358071860|    1358073060|     1200|\n",
      "|000318C2E3E638158...|        Unknown|1358073660|    1358074020|      360|\n",
      "|000318C2E3E638158...|        Unknown|1358074320|    1358074560|      240|\n",
      "|000318C2E3E638158...|        Unknown|1358075040|    1358075400|      360|\n",
      "|000318C2E3E638158...|        Unknown|1358076420|    1358077020|      600|\n",
      "|000318C2E3E638158...|        Unknown|1358077380|    1358077920|      540|\n",
      "|000318C2E3E638158...|        Unknown|1358078280|    1358079060|      780|\n",
      "+--------------------+---------------+----------+--------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lead, avg, col\n",
    "\n",
    "window_spec = Window.partitionBy(\"medallion\").orderBy(\"dropoff_ts\")\n",
    "\n",
    "df_selected = df_selected.withColumn(\"next_pickup_ts\", lead(\"pickup_ts\").over(window_spec))\n",
    "\n",
    "df_selected = df_selected.withColumn(\"wait_time\", col(\"next_pickup_ts\") - col(\"dropoff_ts\"))\n",
    "\n",
    "df_selected = df_selected.filter(col(\"wait_time\").isNotNull())\n",
    "\n",
    "df_selected.select(\"medallion\", \"dropoff_borough\", \"dropoff_ts\", \"next_pickup_ts\", \"wait_time\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+\n",
      "|dropoff_borough|     avg_wait_time|\n",
      "+---------------+------------------+\n",
      "|         Queens| 6368.423432682425|\n",
      "|        Unknown|12206.935332708528|\n",
      "|       Brooklyn| 6554.840325610519|\n",
      "|  Staten Island|           13935.0|\n",
      "|      Manhattan|2048.9211563256895|\n",
      "|          Bronx| 4973.719008264463|\n",
      "+---------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_wait_time = df_selected.groupBy(\"dropoff_borough\").agg(\n",
    "    avg(\"wait_time\").alias(\"avg_wait_time\")\n",
    ")\n",
    "\n",
    "avg_wait_time.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|dropoff_borough|count|\n",
      "+---------------+-----+\n",
      "|         Queens| 4865|\n",
      "|        Unknown| 2134|\n",
      "|       Brooklyn| 3194|\n",
      "|  Staten Island|   12|\n",
      "|      Manhattan|82987|\n",
      "|          Bronx|  363|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_selected.groupBy(\"dropoff_borough\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUERY 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trips that started and ended in the same borough: 81053\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "same_borough_count = df_selected.filter(\n",
    "    (col(\"pickup_borough\") == col(\"dropoff_borough\")) &\n",
    "    (col(\"pickup_borough\") != \"Unknown\") & \n",
    "    (col(\"dropoff_borough\") != \"Unknown\")\n",
    ").count()\n",
    "\n",
    "print(f\"Total trips that started and ended in the same borough: {same_borough_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUERY 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trips that started in one borough and ended in another: 10240\n"
     ]
    }
   ],
   "source": [
    "different_borough_count = df_selected.filter(\n",
    "    (col(\"pickup_borough\") != col(\"dropoff_borough\")) &\n",
    "    (col(\"pickup_borough\") != \"Unknown\") & \n",
    "    (col(\"dropoff_borough\") != \"Unknown\")\n",
    ").count()\n",
    "\n",
    "print(f\"Total trips that started in one borough and ended in another: {different_borough_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
